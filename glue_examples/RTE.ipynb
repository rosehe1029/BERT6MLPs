{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RTE : Recognizing Textual Entailment\n",
    "\n",
    "The Recognizing Textual Entailment(RTE) task is a sentence pair classification task. It consists of sentence pairs drawn from annual text data challenge sets and annotated for textual entailment.\n",
    "\n",
    "See [website](https://aclweb.org/aclwiki/Recognizing_Textual_Entailment) for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sys.path.append(\"../\") \n",
    "from bert_sklearn import BertClassifier\n",
    "\n",
    "DATADIR = os.getcwd() + '/glue_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and extracting RTE...\n",
      "\tCompleted!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 download_glue_data.py --data_dir glue_data --tasks RTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RTE train data size: 2489 \n",
      "RTE dev data size: 277 \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RTE train data size: 2489 \n",
    "RTE dev data size: 277 \n",
    "\"\"\"\n",
    "\n",
    "def read_tsv(filename,quotechar=None):\n",
    "    with open(filename, \"r\", encoding='utf-8') as f:\n",
    "        return list(csv.reader(f,delimiter=\"\\t\",quotechar=quotechar))\n",
    "    \n",
    "\n",
    "def get_rte_df(filename):\n",
    "    df = pd.read_csv(filename, sep='\\t',  encoding = 'utf8',keep_default_na=False)\n",
    "    df=df[['sentence1','sentence2','label']]\n",
    "    df.columns=['text_a','text_b','label']\n",
    "    df = df[pd.notnull(df['label'])]  \n",
    "    df = df[df.label != \"\"]    \n",
    "    return df    \n",
    "\n",
    "def get_rte_data(train_file = DATADIR +'/RTE/train.tsv',\n",
    "                  dev_file = DATADIR + '/RTE/dev.tsv'):\n",
    "    \n",
    "    train = get_rte_df(train_file)\n",
    "    print(\"RTE train data size: %d \"%(len(train)))        \n",
    "    dev = get_rte_df(dev_file)\n",
    "    print(\"RTE dev data size: %d \"%(len(dev)))              \n",
    "    label_list = np.unique(train['label'].values)\n",
    "\n",
    "    \n",
    "    return train,dev,label_list\n",
    "\n",
    "train,dev,label_list = get_rte_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entailment' 'not_entailment']\n"
     ]
    }
   ],
   "source": [
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>text_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Weapons of Mass Destruction Found in Iraq Yet.</td>\n",
       "      <td>Weapons of Mass Destruction Found in Iraq.</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A place of sorrow, after Pope John Paul II die...</td>\n",
       "      <td>Pope Benedict XVI is the new leader of the Rom...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Herceptin was already approved to treat the si...</td>\n",
       "      <td>Herceptin can be used to treat breast cancer.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Judie Vivian, chief executive at ProMedica, a ...</td>\n",
       "      <td>The previous name of Ho Chi Minh City was Saigon.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is due in court later charged with the m...</td>\n",
       "      <td>Paul Stewart Hutchinson is accused of having s...</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_a  \\\n",
       "0  No Weapons of Mass Destruction Found in Iraq Yet.   \n",
       "1  A place of sorrow, after Pope John Paul II die...   \n",
       "2  Herceptin was already approved to treat the si...   \n",
       "3  Judie Vivian, chief executive at ProMedica, a ...   \n",
       "4  A man is due in court later charged with the m...   \n",
       "\n",
       "                                              text_b           label  \n",
       "0         Weapons of Mass Destruction Found in Iraq.  not_entailment  \n",
       "1  Pope Benedict XVI is the new leader of the Rom...      entailment  \n",
       "2      Herceptin can be used to treat breast cancer.      entailment  \n",
       "3  The previous name of Ho Chi Minh City was Saigon.      entailment  \n",
       "4  Paul Stewart Hutchinson is accused of having s...  not_entailment  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn classifier...\n",
      "\n",
      " BertClassifier(bert_model='bert-base-uncased', epochs=4, eval_batch_size=8,\n",
      "        fp16=False, gradient_accumulation_steps=1, label_list=None,\n",
      "        learning_rate=3e-05, local_rank=-1, logfile='bert_sklearn.log',\n",
      "        loss_scale=0, max_seq_length=96, num_mlp_hiddens=500,\n",
      "        num_mlp_layers=0, random_state=42, restore_file=None,\n",
      "        train_batch_size=32, use_cuda=True, validation_fraction=0,\n",
      "        warmup_proportion=0.1) \n",
      "\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "train data size: 2489, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 78/78 [00:46<00:00,  1.73it/s, loss=0.717]\n",
      "Training: 100%|██████████| 78/78 [00:46<00:00,  1.75it/s, loss=0.636]\n",
      "Training: 100%|██████████| 78/78 [00:48<00:00,  1.64it/s, loss=0.417]\n",
      "Training: 100%|██████████| 78/78 [00:52<00:00,  1.50it/s, loss=0.287]\n",
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.62%\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    entailment       0.63      0.79      0.70       146\n",
      "not_entailment       0.67      0.49      0.57       131\n",
      "\n",
      "     micro avg       0.65      0.65      0.65       277\n",
      "     macro avg       0.65      0.64      0.63       277\n",
      "  weighted avg       0.65      0.65      0.64       277\n",
      "\n",
      "CPU times: user 2min 10s, sys: 1min 13s, total: 3min 23s\n",
      "Wall time: 3min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = train[['text_a','text_b']]\n",
    "y_train = train['label']\n",
    "\n",
    "# define model\n",
    "model = BertClassifier()\n",
    "model.epochs = 4\n",
    "model.learning_rate = 3e-5\n",
    "model.max_seq_length = 96\n",
    "model.validation_fraction = 0\n",
    "\n",
    "print('\\n',model,'\\n')\n",
    "\n",
    "# fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# test model on dev\n",
    "test = dev\n",
    "X_test = test[['text_a','text_b']]\n",
    "y_test = test['label']\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy: %0.2f%%\"%(metrics.accuracy_score(y_pred,y_test) * 100))\n",
    "\n",
    "target_names = ['entailment', 'not_entailment']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
