{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoLA : Corpus of Linguistic Acceptability\n",
    "\n",
    "The Corpus of Linguistic Acceptability(CoLA) is a single sentence classification task. \n",
    "It consists of sentences drawn from linguistic publications and annotated for being acceptable English or not.\n",
    "\n",
    "See [website](https://nyu-mll.github.io/CoLA/) and [paper](https://arxiv.org/abs/1805.12471) for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sys.path.append(\"../\") \n",
    "from bert_sklearn import BertClassifier\n",
    "from bert_sklearn import load_model\n",
    "\n",
    "DATADIR = os.getcwd() + '/glue_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and extracting CoLA...\n",
      "\tCompleted!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 download_glue_data.py --data_dir glue_data --tasks CoLA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoLA train data size: 8551 \n",
      "CoLA dev data size: 1043 \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CoLA train data size: 8551 \n",
    "CoLA dev data size: 1043 \n",
    "\"\"\"\n",
    "\n",
    "def get_cola_df(filename,cols = [3,1]):\n",
    "    df = pd.read_csv(filename, sep='\\t',  encoding = 'utf8',keep_default_na=False,header=None)\n",
    "    df = df[cols]\n",
    "    df.columns=['text','label']\n",
    "    return df\n",
    "\n",
    "def get_cola_data(train_file = DATADIR+'/CoLA/train.tsv', \n",
    "                   dev_file =  DATADIR+'/CoLA/dev.tsv'):\n",
    "    \n",
    "    train = get_cola_df(train_file)\n",
    "    print(\"CoLA train data size: %d \"%(len(train)))\n",
    "    dev = get_cola_df(dev_file)\n",
    "    print(\"CoLA dev data size: %d \"%(len(dev)))\n",
    "\n",
    "    label_list = np.unique(train['label'].values)\n",
    "    return train,dev,label_list  \n",
    "                  \n",
    "train,dev,label_list =  get_cola_data()             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our friends won't buy this analysis, let alone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One more pseudo generalization and I'm giving up.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One more pseudo generalization or I'm giving up.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The more we study verbs, the crazier they get.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Day by day the facts are getting murkier.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Our friends won't buy this analysis, let alone...      1\n",
       "1  One more pseudo generalization and I'm giving up.      1\n",
       "2   One more pseudo generalization or I'm giving up.      1\n",
       "3     The more we study verbs, the crazier they get.      1\n",
       "4          Day by day the facts are getting murkier.      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn classifier...\n",
      "\n",
      " BertClassifier(bert_model='bert-base-uncased', epochs=3, eval_batch_size=8,\n",
      "        fp16=False, gradient_accumulation_steps=2, label_list=None,\n",
      "        learning_rate=2e-05, local_rank=-1, logfile='bert_sklearn.log',\n",
      "        loss_scale=0, max_seq_length=128, num_mlp_hiddens=500,\n",
      "        num_mlp_layers=0, random_state=42, restore_file=None,\n",
      "        train_batch_size=32, use_cuda=True, validation_fraction=0,\n",
      "        warmup_proportion=0.1) \n",
      "\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "train data size: 8551, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 535/535 [04:49<00:00,  1.98it/s, loss=0.515]\n",
      "Training: 100%|██████████| 535/535 [04:51<00:00,  1.98it/s, loss=0.247]\n",
      "Training: 100%|██████████| 535/535 [04:51<00:00,  1.98it/s, loss=0.155]\n",
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.84%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.82      0.57      0.67       322\n",
      "   positive       0.83      0.94      0.88       721\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1043\n",
      "\n",
      "\n",
      "Mathews Correlation: 57.79\n",
      "CPU times: user 12min 39s, sys: 6min 8s, total: 18min 48s\n",
      "Wall time: 14min 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "X_train = train['text']\n",
    "y_train = train['label']\n",
    "\n",
    "# define model\n",
    "model = BertClassifier()\n",
    "model.epochs = 3\n",
    "model.validation_fraction = 0\n",
    "model.learning_rate = 2e-5\n",
    "model.max_seq_length = 128\n",
    "model.gradient_accumulation_steps = 2\n",
    "\n",
    "print('\\n',model,'\\n')\n",
    "\n",
    "# fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# test model on dev\n",
    "test = dev\n",
    "X_test = test['text']\n",
    "y_test = test['label']\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy: %0.2f%%\"%(metrics.accuracy_score(y_pred,y_test) * 100))\n",
    "print(classification_report(y_test, y_pred, target_names=['negative','positive']))\n",
    "\n",
    "# Mathews correlation coefficient\n",
    "print(\"\\nMathews Correlation: %0.2f\"%(matthews_corrcoef(y_test, y_pred) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
